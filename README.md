# AI 재귀 학습: 붕괴 임계점과 최적의 인간-AI 데이터 비율

> 반복적으로 학습된 AI의 성능 저하와 인간-AI 데이터 혼합 비율의 최적값을 정량적으로 분석한 연구입니다.
> 2025년도 한성과학고등학교 정보 분야 과제연구 최우수상으로 선정되었습니다.

---

## 📘 개요

본 프로젝트는 AI 모델이 스스로 생성한 데이터를 반복적으로 학습할 때 발생하는 **AI 붕괴(AI Collapse)** 현상을 정량적으로 분석합니다. 시계열 예측에 특화된 LSTM(Long Short-Term Memory) 모델을 활용하여, 성능 붕괴 시점과 그 경향성을 파악하고, AI 모델의 장기적 안정성을 확보하기 위한 **인간 생성 데이터와 AI 생성 데이터의 최적 혼합 비율**을 실험적으로 도출합니다.

---

## 📌 연구 동기

최근 AI가 생성한 데이터가 다시 AI 학습에 사용되는 구조가 점점 일반화되고 있습니다. 이러한 재귀 학습 구조는 데이터 다양성을 저해하고, 결과적으로 AI 모델이 점차 원본 데이터 분포에서 벗어나 성능이 붕괴되는 현상을 야기할 수 있습니다.

본 연구는 다음의 두 가지 주요 목적을 갖습니다:

* 재귀 학습 중 성능 붕괴가 발생하는 시점과 경향성 분석
* AI 모델 성능을 장기적으로 유지할 수 있는 **인간 vs AI 데이터의 최적 비율** 도출

---

## 🧪 연구 방법

### 실험 1: LSTM 재귀 학습

* 1세대 LSTM 모델을 원본(인간 생성) 데이터로 학습
* 해당 모델이 생성한 예측값을 다음 세대 학습 데이터로 사용
* 이를 반복하여 총 45세대까지 학습 수행
* 각 세대의 예측값과 실제값 간의 오차를 MAE, RMSE, Huber, Log-Cosh 손실함수로 측정
* 성능 붕괴 시점을 시각화 및 분석

### 실험 2: 인간-AI 데이터 비율에 따른 성능 분석

* 1세대 모델이 생성한 데이터를 100% AI 데이터로 간주
* 원본 데이터를 100% 인간 데이터로 간주
* 이진 탐색 알고리즘을 활용해 다양한 혼합 비율 생성 (예: 50%, 75%, 87.5% 등)
* 각 비율로 모델을 학습시키고, 10세대에 걸쳐 예측 성능 평가
* 손실값이 가장 낮은 비율을 최적 비율로 설정

---

## 📊 주요 결과

### 재귀 학습의 성능 붕괴

* 3세대까지는 손실값이 안정적으로 유지됨
* 6세대부터 손실값이 급격히 증가하는 양상 확인
* 20세대 이후부터는 손실값이 주기적으로 진동하며 붕괴가 본격화
* 평균적으로 모든 변수에서 약 5% 이상의 손실 증가가 발생
* `season`, `weekday`, `hum` 등의 변수는 지표가 0.92 이하로 반복적으로 하락

### 최적의 인간-AI 데이터 비율

* **87.5% 인간 데이터 + 12.5% AI 데이터** 비율에서 가장 낮은 손실 기록
* 50:50 혼합 비율에서는 모든 변수에서 성능 급락
* `hum`, `holiday`: Huber 손실함수에서 민감하게 반응
* `weekday`, `workingday`: Log-Cosh 손실함수에서 50% 비율에서 손실 최댓값 기록
* 전체적으로 75% 이상 인간 데이터를 포함할 경우 성능이 회복되는 양상

---

## 📈 시각화 자료

* 세대별 손실 함수 변화 그래프 (MAE, RMSE, Huber, Log-Cosh 등)
* 데이터 혼합 비율에 따른 변수별 손실 함수 변화
* 성능 붕괴 시점과 패턴을 보여주는 시계열 시각화

---

## 🧩 향후 과제

* Transformer 및 자연어 처리 모델 등 다양한 구조로 확장
* 노이즈, 인간 오류, 구조적 데이터 편향 등의 조건 실험
* 변수별 손실 민감도를 반영한 정밀한 성능 평가 체계 구축
* 인간 데이터 확보 비용을 고려한 효율적인 데이터 수집 전략 연구

---
